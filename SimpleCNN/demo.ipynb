{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm76McV3OFl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from sklearn import metrics\n",
        "from scratch_cnn import ScratchCNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BGmhViLOfxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mnistデータでデモ\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2])\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcJsad7JOjAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2df0731f-f2a4-4e3f-a848-cca3a09ca8a1"
      },
      "source": [
        "%%time\n",
        "cnn = ScratchCNN(epoch=1, lr=0.001, verbose=True, initializer=\"he\", optimizer=\"adagrad\", activation=\"relu\",\n",
        "                 batch_size=200, n_filters=30, hidden_nodes=100, filter_size=(3, 3), padding_size=(1, 1),\n",
        "                 stride_size=(1, 1))\n",
        "cnn.fit(X_train, y_train, X_val, y_val)\n",
        "y_pred = cnn.predict(X_test)\n",
        "print(\"Accuracy:{}\".format(metrics.accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data learning process\n",
            "\n",
            "train_loss:4.924425526187967\n",
            "train_loss:8.98732453051011\n",
            "train_loss:8.81921055402226\n",
            "train_loss:7.897896322343939\n",
            "train_loss:6.525386312128239\n",
            "train_loss:5.352850071886214\n",
            "train_loss:3.237297826664418\n",
            "train_loss:2.279280368354806\n",
            "train_loss:1.7360245068313367\n",
            "train_loss:1.6022470305811571\n",
            "train_loss:1.4122699913122603\n",
            "train_loss:1.3267430262378468\n",
            "train_loss:1.2891077354788567\n",
            "train_loss:1.1098137605567884\n",
            "train_loss:1.2095655201082625\n",
            "train_loss:1.2332269588376759\n",
            "train_loss:1.0193979766403067\n",
            "train_loss:1.013789526783946\n",
            "train_loss:0.9859342179090058\n",
            "train_loss:1.0821221808253332\n",
            "train_loss:0.8084567665138934\n",
            "train_loss:0.8878211429851074\n",
            "train_loss:0.9537929947738566\n",
            "train_loss:0.8407657540540936\n",
            "train_loss:0.8225563014868282\n",
            "train_loss:0.8655951529937504\n",
            "train_loss:0.8950005422121856\n",
            "train_loss:0.8618099825551556\n",
            "train_loss:0.777041132702933\n",
            "train_loss:0.8194981923853356\n",
            "train_loss:0.794994119985191\n",
            "train_loss:0.7389397902462352\n",
            "train_loss:0.8152084633473143\n",
            "train_loss:0.8818957995359626\n",
            "train_loss:0.734101791510405\n",
            "train_loss:0.6568762916811481\n",
            "train_loss:0.7008723262336765\n",
            "train_loss:0.7383349926176836\n",
            "train_loss:0.790573165566842\n",
            "train_loss:0.5596008986271277\n",
            "train_loss:0.763815438946396\n",
            "train_loss:0.5811918257087534\n",
            "train_loss:0.8381582282839923\n",
            "train_loss:0.6656120460641859\n",
            "train_loss:0.6629668918702901\n",
            "train_loss:0.6742903032865157\n",
            "train_loss:0.7225609566877691\n",
            "train_loss:0.651543077458201\n",
            "train_loss:0.6509329389645273\n",
            "train_loss:0.6292485046742123\n",
            "train_loss:0.7766043634297347\n",
            "train_loss:0.5798098509157594\n",
            "train_loss:0.6174041673217543\n",
            "train_loss:0.6692713389752847\n",
            "train_loss:0.67929669377414\n",
            "train_loss:0.6938061061768411\n",
            "train_loss:0.5712813802666646\n",
            "train_loss:0.6840749297836203\n",
            "train_loss:0.5027983130271264\n",
            "train_loss:0.5950491356739407\n",
            "train_loss:0.619983422562201\n",
            "train_loss:0.5537266710949814\n",
            "train_loss:0.6549092471267612\n",
            "train_loss:0.6051134479435425\n",
            "train_loss:0.5903465064815953\n",
            "train_loss:0.6065148421734494\n",
            "train_loss:0.5860300116212411\n",
            "train_loss:0.5390311192426631\n",
            "train_loss:0.6329210012698512\n",
            "train_loss:0.5767955385392614\n",
            "train_loss:0.5463467105109349\n",
            "train_loss:0.47017554719604154\n",
            "train_loss:0.6335549773648207\n",
            "train_loss:0.5382702406929717\n",
            "train_loss:0.5946154827239785\n",
            "train_loss:0.5417021337520123\n",
            "train_loss:0.5728136691528439\n",
            "train_loss:0.4691049599382596\n",
            "train_loss:0.5916887314937371\n",
            "train_loss:0.5581302139153776\n",
            "train_loss:0.5546037356511794\n",
            "train_loss:0.6259687804035892\n",
            "train_loss:0.6154545039129367\n",
            "train_loss:0.604728344799036\n",
            "train_loss:0.4964494399075503\n",
            "train_loss:0.5431528220431864\n",
            "train_loss:0.4894543775202456\n",
            "train_loss:0.4464214092567307\n",
            "train_loss:0.49077643621593514\n",
            "train_loss:0.42502893727153285\n",
            "train_loss:0.5272312932132915\n",
            "train_loss:0.5310933197341206\n",
            "train_loss:0.5413681177937848\n",
            "train_loss:0.48215561844281507\n",
            "train_loss:0.45321786532745095\n",
            "train_loss:0.5105417829876913\n",
            "train_loss:0.42183892013059626\n",
            "train_loss:0.5507126542149576\n",
            "train_loss:0.5518898089043073\n",
            "train_loss:0.5576166195585212\n",
            "train_loss:0.4003610241653421\n",
            "train_loss:0.37359517650439683\n",
            "train_loss:0.5833812372612841\n",
            "train_loss:0.46071504070980823\n",
            "train_loss:0.521677707420342\n",
            "train_loss:0.5022487243363567\n",
            "train_loss:0.583773521764794\n",
            "train_loss:0.5204124479363358\n",
            "train_loss:0.47824181667922416\n",
            "train_loss:0.5271412868759319\n",
            "train_loss:0.37587852105769587\n",
            "train_loss:0.3949050611926202\n",
            "train_loss:0.5477511114993864\n",
            "train_loss:0.4062149574998271\n",
            "train_loss:0.45382868793210557\n",
            "train_loss:0.4342935672731709\n",
            "train_loss:0.4668309372876648\n",
            "train_loss:0.461635532376569\n",
            "train_loss:0.39494387771655837\n",
            "train_loss:0.46860655864530587\n",
            "train_loss:0.41203834033286296\n",
            "train_loss:0.48277702423773294\n",
            "train_loss:0.46800031597169095\n",
            "train_loss:0.34661333986303083\n",
            "train_loss:0.3732514116992838\n",
            "train_loss:0.45378940134479623\n",
            "train_loss:0.4122124550295487\n",
            "train_loss:0.46385325468485183\n",
            "train_loss:0.4975301635776933\n",
            "train_loss:0.48755310377071853\n",
            "train_loss:0.4981577280887508\n",
            "train_loss:0.48664883264846365\n",
            "train_loss:0.5013762035236191\n",
            "train_loss:0.5112553160909048\n",
            "train_loss:0.35754302700837237\n",
            "train_loss:0.3767616239417403\n",
            "train_loss:0.3309449765487111\n",
            "train_loss:0.4088713523892426\n",
            "train_loss:0.419468419996771\n",
            "train_loss:0.3597505681984643\n",
            "train_loss:0.44233957578506733\n",
            "train_loss:0.43887814517332047\n",
            "train_loss:0.41633519713696926\n",
            "train_loss:0.4721127666482954\n",
            "train_loss:0.4342777654516929\n",
            "train_loss:0.590286779205169\n",
            "train_loss:0.4384714602114242\n",
            "train_loss:0.38909781396055976\n",
            "train_loss:0.35260523663041793\n",
            "train_loss:0.42447004315332926\n",
            "train_loss:0.4163474000521133\n",
            "train_loss:0.3872811844527413\n",
            "train_loss:0.3362128426385363\n",
            "train_loss:0.423485292892317\n",
            "train_loss:0.5040634829782468\n",
            "train_loss:0.42920112256337106\n",
            "train_loss:0.4381855636785228\n",
            "train_loss:0.4324285217196686\n",
            "train_loss:0.4004728821745623\n",
            "train_loss:0.3970516660690883\n",
            "train_loss:0.4541073365546204\n",
            "train_loss:0.3722504994029797\n",
            "train_loss:0.3687670988995792\n",
            "train_loss:0.34264473821106767\n",
            "train_loss:0.4221533569631776\n",
            "train_loss:0.33089591295680015\n",
            "train_loss:0.4029382109124178\n",
            "train_loss:0.409152721206438\n",
            "train_loss:0.4368938559286143\n",
            "train_loss:0.48195848045929046\n",
            "train_loss:0.5484580923036438\n",
            "train_loss:0.4060688967983947\n",
            "train_loss:0.315707158244342\n",
            "train_loss:0.34979869308160005\n",
            "train_loss:0.5243987487282691\n",
            "train_loss:0.3726798372101095\n",
            "train_loss:0.4391992835554079\n",
            "train_loss:0.47883606484214125\n",
            "train_loss:0.4036812753341269\n",
            "train_loss:0.42094552677257324\n",
            "train_loss:0.36616507410255783\n",
            "train_loss:0.45128995642739417\n",
            "train_loss:0.4816329924414661\n",
            "train_loss:0.48613904487658016\n",
            "train_loss:0.3868381415294656\n",
            "train_loss:0.4322486880656494\n",
            "train_loss:0.37782751703393386\n",
            "train_loss:0.3719802913811249\n",
            "train_loss:0.3269158298855847\n",
            "train_loss:0.3954220024121251\n",
            "train_loss:0.3296001873398959\n",
            "train_loss:0.39659720389503034\n",
            "train_loss:0.4175503030134044\n",
            "train_loss:0.3267852582082154\n",
            "train_loss:0.42318722035117007\n",
            "train_loss:0.37779393752867846\n",
            "train_loss:0.3907585672147803\n",
            "train_loss:0.5073203480709456\n",
            "train_loss:0.4390066413077635\n",
            "train_loss:0.38662637921555904\n",
            "train_loss:0.41766556221096335\n",
            "train_loss:0.34862396935998186\n",
            "train_loss:0.38129555135764437\n",
            "train_loss:0.4109153252968713\n",
            "train_loss:0.3375709988540517\n",
            "train_loss:0.40387250099870015\n",
            "train_loss:0.38358003052285583\n",
            "train_loss:0.3127392391100826\n",
            "train_loss:0.389167876812839\n",
            "train_loss:0.5522134717935405\n",
            "train_loss:0.4100901820518349\n",
            "train_loss:0.3466148943223192\n",
            "train_loss:0.45629750472642966\n",
            "train_loss:0.38166127540663\n",
            "train_loss:0.3512470418920721\n",
            "train_loss:0.2929587369827333\n",
            "train_loss:0.47762633410840266\n",
            "train_loss:0.3508787386017947\n",
            "train_loss:0.29689736856289084\n",
            "train_loss:0.2953108970265655\n",
            "train_loss:0.34974623794946347\n",
            "train_loss:0.4094417163585274\n",
            "train_loss:0.4100178166731905\n",
            "train_loss:0.3478470473965736\n",
            "train_loss:0.4572226697265272\n",
            "train_loss:0.380777298821199\n",
            "train_loss:0.4285843087382966\n",
            "train_loss:0.340177571724348\n",
            "train_loss:0.4886337013065034\n",
            "train_loss:0.29237330912063464\n",
            "train_loss:0.408642665946559\n",
            "train_loss:0.3725918754747147\n",
            "train_loss:0.379047154763299\n",
            "train_loss:0.3706665315747743\n",
            "train_loss:0.37205831590214955\n",
            "train_loss:0.2796117596680959\n",
            "train_loss:0.39757142227956893\n",
            "train_loss:0.40575717524551197\n",
            "train_loss:0.3010587749029606\n",
            "train_loss:0.4091518703054189\n",
            "epoch:0  train_loss:0.40915187, train_acc:0.89502083, val_acc:0.89083333\n",
            "train_loss:0.30645633216225837\n",
            "train_loss:0.4061514534118728\n",
            "train_loss:0.3955405579839432\n",
            "train_loss:0.3555451112470156\n",
            "train_loss:0.37076761529626345\n",
            "train_loss:0.39094447882750655\n",
            "train_loss:0.37731549907746165\n",
            "train_loss:0.4417836850238421\n",
            "train_loss:0.3477092204368708\n",
            "train_loss:0.350320231888052\n",
            "train_loss:0.338366409196974\n",
            "train_loss:0.41881087701274977\n",
            "train_loss:0.3136515734001532\n",
            "train_loss:0.3037097629384073\n",
            "train_loss:0.3496181225025669\n",
            "train_loss:0.32846891382262816\n",
            "train_loss:0.39177631090306764\n",
            "train_loss:0.3397887849846537\n",
            "train_loss:0.3382866111390362\n",
            "train_loss:0.3649839131124758\n",
            "train_loss:0.34081681601265956\n",
            "train_loss:0.40950504826567974\n",
            "train_loss:0.3502718489550404\n",
            "train_loss:0.28867249800107525\n",
            "train_loss:0.3390172801093923\n",
            "train_loss:0.40403444703859115\n",
            "train_loss:0.4236297526788599\n",
            "train_loss:0.4421362838962192\n",
            "train_loss:0.3331489138503275\n",
            "train_loss:0.34301317538950005\n",
            "train_loss:0.3049723435492871\n",
            "train_loss:0.32631529533644754\n",
            "train_loss:0.34668472239868364\n",
            "train_loss:0.5124823927827634\n",
            "train_loss:0.31712739214431973\n",
            "train_loss:0.33558098222406657\n",
            "train_loss:0.35069040643527244\n",
            "train_loss:0.3695809402439928\n",
            "train_loss:0.42144150567056415\n",
            "train_loss:0.21686655022234214\n",
            "train_loss:0.4342341893530382\n",
            "train_loss:0.30760656613585396\n",
            "train_loss:0.46318853537800436\n",
            "train_loss:0.25290624042965665\n",
            "train_loss:0.3237927344649468\n",
            "train_loss:0.3595566132376467\n",
            "train_loss:0.35551839867542356\n",
            "train_loss:0.3611986755916098\n",
            "train_loss:0.3091940858435857\n",
            "train_loss:0.2948047181102587\n",
            "train_loss:0.46749065990191196\n",
            "train_loss:0.26191889128087825\n",
            "train_loss:0.339410113692918\n",
            "train_loss:0.38488931983453084\n",
            "train_loss:0.38471741763468825\n",
            "train_loss:0.4267410014835383\n",
            "train_loss:0.3271461310169167\n",
            "train_loss:0.412235962393806\n",
            "train_loss:0.2724912436618046\n",
            "train_loss:0.36396331982714686\n",
            "train_loss:0.30540153887055554\n",
            "train_loss:0.3084338824808785\n",
            "train_loss:0.42699475164183626\n",
            "train_loss:0.36450375477716535\n",
            "train_loss:0.3570416618569648\n",
            "train_loss:0.38884208274592014\n",
            "train_loss:0.35642221091564197\n",
            "train_loss:0.3435195021011219\n",
            "train_loss:0.3852265473592071\n",
            "train_loss:0.3141557489368358\n",
            "train_loss:0.35469670876773157\n",
            "train_loss:0.2736389889964349\n",
            "train_loss:0.4083555574354032\n",
            "train_loss:0.33883207176700475\n",
            "train_loss:0.4078457604076152\n",
            "train_loss:0.3468766100208213\n",
            "train_loss:0.35334953798763186\n",
            "train_loss:0.2691626763564566\n",
            "train_loss:0.40576109717446424\n",
            "train_loss:0.356753599806932\n",
            "train_loss:0.36854423565347555\n",
            "train_loss:0.4031087563291979\n",
            "train_loss:0.44165362312192236\n",
            "train_loss:0.3915919854004353\n",
            "train_loss:0.30948383723700507\n",
            "train_loss:0.35959938940523756\n",
            "train_loss:0.30926288803607416\n",
            "train_loss:0.29353503641236905\n",
            "train_loss:0.30790419702272276\n",
            "train_loss:0.22710180373341032\n",
            "train_loss:0.35246369226124485\n",
            "train_loss:0.3676514239065671\n",
            "train_loss:0.38235089018454266\n",
            "train_loss:0.32652654394860237\n",
            "train_loss:0.29707723739395886\n",
            "train_loss:0.3497424935698359\n",
            "train_loss:0.2950843869018426\n",
            "train_loss:0.38099558383721766\n",
            "train_loss:0.3758289671663559\n",
            "train_loss:0.36604750222683125\n",
            "train_loss:0.25718296563884563\n",
            "train_loss:0.2393770983476928\n",
            "train_loss:0.4242307507138116\n",
            "train_loss:0.3393504195703403\n",
            "train_loss:0.3745160952798931\n",
            "train_loss:0.3484067265643982\n",
            "train_loss:0.44732082655285327\n",
            "train_loss:0.3509746723497488\n",
            "train_loss:0.32285542249199184\n",
            "train_loss:0.3621567158862953\n",
            "train_loss:0.2367506141123178\n",
            "train_loss:0.29280862565328386\n",
            "train_loss:0.40530127029427193\n",
            "train_loss:0.26162525874514136\n",
            "train_loss:0.3050991020611059\n",
            "train_loss:0.30480046654490134\n",
            "train_loss:0.30485786439966445\n",
            "train_loss:0.32292557715634784\n",
            "train_loss:0.29376929355519155\n",
            "train_loss:0.3324794388477137\n",
            "train_loss:0.2894658299963939\n",
            "train_loss:0.34195081089079066\n",
            "train_loss:0.3530307681850393\n",
            "train_loss:0.21893237070475735\n",
            "train_loss:0.24898526229734966\n",
            "train_loss:0.3495836246000117\n",
            "train_loss:0.29281985483811646\n",
            "train_loss:0.3475126958386107\n",
            "train_loss:0.3587177753997905\n",
            "train_loss:0.369461451820777\n",
            "train_loss:0.38501536458774843\n",
            "train_loss:0.3378222536742306\n",
            "train_loss:0.40182094567447535\n",
            "train_loss:0.3884773218914963\n",
            "train_loss:0.23851085398589578\n",
            "train_loss:0.24270373775687584\n",
            "train_loss:0.23063821740856397\n",
            "train_loss:0.30366816064109065\n",
            "train_loss:0.30657204033542906\n",
            "train_loss:0.27399198407170317\n",
            "train_loss:0.3384632763152527\n",
            "train_loss:0.3371166493232962\n",
            "train_loss:0.3066690181746927\n",
            "train_loss:0.36216331616742276\n",
            "train_loss:0.33988785887817097\n",
            "train_loss:0.47549095521996904\n",
            "train_loss:0.3098734912964786\n",
            "train_loss:0.2738776083026599\n",
            "train_loss:0.2600748036617226\n",
            "train_loss:0.29595488184602325\n",
            "train_loss:0.32362159433471005\n",
            "train_loss:0.2912300894559177\n",
            "train_loss:0.22092663415653913\n",
            "train_loss:0.3035066398977185\n",
            "train_loss:0.43596996979421293\n",
            "train_loss:0.3106380403541598\n",
            "train_loss:0.34229357137946304\n",
            "train_loss:0.3353501107759391\n",
            "train_loss:0.29178753625476966\n",
            "train_loss:0.28715029745614734\n",
            "train_loss:0.34170859068780934\n",
            "train_loss:0.27770346887246045\n",
            "train_loss:0.26044843711047244\n",
            "train_loss:0.2503047781086509\n",
            "train_loss:0.31998434376427815\n",
            "train_loss:0.251596401690208\n",
            "train_loss:0.30559894005399224\n",
            "train_loss:0.292564512279452\n",
            "train_loss:0.3040965328885035\n",
            "train_loss:0.39131348909273983\n",
            "train_loss:0.43084181689163914\n",
            "train_loss:0.3186079490666897\n",
            "train_loss:0.23345448410314065\n",
            "train_loss:0.2647365084861949\n",
            "train_loss:0.443649720460752\n",
            "train_loss:0.2862823619171828\n",
            "train_loss:0.34836839483799736\n",
            "train_loss:0.3897028859349038\n",
            "train_loss:0.29640437472232073\n",
            "train_loss:0.3337722411521692\n",
            "train_loss:0.2649498392311541\n",
            "train_loss:0.3858403382941252\n",
            "train_loss:0.38978190569770793\n",
            "train_loss:0.39547215510885453\n",
            "train_loss:0.3108249785379866\n",
            "train_loss:0.3655259791191136\n",
            "train_loss:0.2950113911125851\n",
            "train_loss:0.31105670094641225\n",
            "train_loss:0.26882956363184257\n",
            "train_loss:0.3073746372622342\n",
            "train_loss:0.25062002948629475\n",
            "train_loss:0.3249195760743996\n",
            "train_loss:0.33395646340492163\n",
            "train_loss:0.24526459218213403\n",
            "train_loss:0.34284526445367464\n",
            "train_loss:0.28308575977943223\n",
            "train_loss:0.3284133472423989\n",
            "train_loss:0.3962737397316771\n",
            "train_loss:0.3784040633734292\n",
            "train_loss:0.31791024047336675\n",
            "train_loss:0.3259305385862299\n",
            "train_loss:0.2880796351489259\n",
            "train_loss:0.32624457372379695\n",
            "train_loss:0.35423906397145755\n",
            "train_loss:0.254461708038161\n",
            "train_loss:0.32255724495843596\n",
            "train_loss:0.3049251146859393\n",
            "train_loss:0.24825080594411988\n",
            "train_loss:0.32182118172818563\n",
            "train_loss:0.47488127968631616\n",
            "train_loss:0.3347609856919036\n",
            "train_loss:0.2666593339832059\n",
            "train_loss:0.38241740698674304\n",
            "train_loss:0.3004716536554961\n",
            "train_loss:0.29573320830968197\n",
            "train_loss:0.2154966474500143\n",
            "train_loss:0.3966024582631766\n",
            "train_loss:0.2779392192130532\n",
            "train_loss:0.22673998258357778\n",
            "train_loss:0.22576028105667298\n",
            "train_loss:0.2628053731302353\n",
            "train_loss:0.3368956265656559\n",
            "train_loss:0.3323773897225689\n",
            "train_loss:0.2756073022564007\n",
            "train_loss:0.40938076157688713\n",
            "train_loss:0.2986407134575334\n",
            "train_loss:0.35669489938774007\n",
            "train_loss:0.26339713129090425\n",
            "train_loss:0.4150937281418412\n",
            "train_loss:0.25234464634343395\n",
            "train_loss:0.34311878355780595\n",
            "train_loss:0.29079610948044227\n",
            "train_loss:0.31509148952947724\n",
            "train_loss:0.3038081587423675\n",
            "train_loss:0.3157428455070436\n",
            "train_loss:0.2234766355774368\n",
            "train_loss:0.334317861088519\n",
            "train_loss:0.33454181769903996\n",
            "train_loss:0.23740000018635896\n",
            "train_loss:0.33897208436973186\n",
            "epoch:1  train_loss:0.33897208, train_acc:0.91331250, val_acc:0.91150000\n",
            "train_loss:0.23641693449518378\n",
            "train_loss:0.3523865284088547\n",
            "train_loss:0.3151188816282755\n",
            "train_loss:0.2991912521055876\n",
            "train_loss:0.318203045578568\n",
            "train_loss:0.34060743158946977\n",
            "train_loss:0.3156682351260927\n",
            "train_loss:0.3882438792766301\n",
            "train_loss:0.2941914229740562\n",
            "train_loss:0.29018955858360757\n",
            "train_loss:0.2750821323078728\n",
            "train_loss:0.34636215043058144\n",
            "train_loss:0.24089904969721715\n",
            "train_loss:0.25105903418530756\n",
            "train_loss:0.2872996111762767\n",
            "train_loss:0.2738977650134386\n",
            "train_loss:0.3214957483751145\n",
            "train_loss:0.27087044295348023\n",
            "train_loss:0.2903540455236174\n",
            "train_loss:0.2977863031411844\n",
            "train_loss:0.2873044095846936\n",
            "train_loss:0.3602631863028607\n",
            "train_loss:0.29305872304969766\n",
            "train_loss:0.22767161726191548\n",
            "train_loss:0.2931404419559837\n",
            "train_loss:0.35842426732605565\n",
            "train_loss:0.36470588551369315\n",
            "train_loss:0.3922612803913833\n",
            "train_loss:0.2881665207465715\n",
            "train_loss:0.2861331914287687\n",
            "train_loss:0.2500399034689364\n",
            "train_loss:0.26281792030361983\n",
            "train_loss:0.2849890767169754\n",
            "train_loss:0.4617494765423723\n",
            "train_loss:0.2544710656604278\n",
            "train_loss:0.288874238582848\n",
            "train_loss:0.30725951966758136\n",
            "train_loss:0.3144757609811729\n",
            "train_loss:0.3759300968095011\n",
            "train_loss:0.17754406416629884\n",
            "train_loss:0.36694782778396723\n",
            "train_loss:0.26297867039586026\n",
            "train_loss:0.39972968494226263\n",
            "train_loss:0.2034610493478567\n",
            "train_loss:0.28135837335776737\n",
            "train_loss:0.30946909465565187\n",
            "train_loss:0.30378959265618916\n",
            "train_loss:0.3089018889079589\n",
            "train_loss:0.24842385658692734\n",
            "train_loss:0.22875912529548242\n",
            "train_loss:0.39415068125851255\n",
            "train_loss:0.21779775465829146\n",
            "train_loss:0.28507242792359694\n",
            "train_loss:0.3310655230364316\n",
            "train_loss:0.32276469133175906\n",
            "train_loss:0.369888805808156\n",
            "train_loss:0.27885418314939353\n",
            "train_loss:0.36123688544320365\n",
            "train_loss:0.23076149850043362\n",
            "train_loss:0.3136695685621089\n",
            "train_loss:0.2419660064184383\n",
            "train_loss:0.25350297358718166\n",
            "train_loss:0.37269849322927806\n",
            "train_loss:0.3182747285901748\n",
            "train_loss:0.3085818142303339\n",
            "train_loss:0.3416934384835\n",
            "train_loss:0.3035070913203501\n",
            "train_loss:0.29614998727875014\n",
            "train_loss:0.32054683803947304\n",
            "train_loss:0.26568272486501643\n",
            "train_loss:0.2991105622614563\n",
            "train_loss:0.23023836006007709\n",
            "train_loss:0.34890280460392714\n",
            "train_loss:0.2846677311545468\n",
            "train_loss:0.3589391149705914\n",
            "train_loss:0.28675909621549617\n",
            "train_loss:0.29645903213747116\n",
            "train_loss:0.22023434994863095\n",
            "train_loss:0.36126115787406043\n",
            "train_loss:0.29527366973022495\n",
            "train_loss:0.3313956191534966\n",
            "train_loss:0.342173709629413\n",
            "train_loss:0.39949654664430406\n",
            "train_loss:0.33244341767867175\n",
            "train_loss:0.26689496417095043\n",
            "train_loss:0.3088507727075789\n",
            "train_loss:0.2655085929731894\n",
            "train_loss:0.25667529699795133\n",
            "train_loss:0.2587425320524705\n",
            "train_loss:0.1752554537330534\n",
            "train_loss:0.29826042736640324\n",
            "train_loss:0.3224549829407762\n",
            "train_loss:0.3342310801056071\n",
            "train_loss:0.28705497242127104\n",
            "train_loss:0.24510502203786344\n",
            "train_loss:0.3035807777093803\n",
            "train_loss:0.25652521945045914\n",
            "train_loss:0.3310797166741547\n",
            "train_loss:0.32696784059188105\n",
            "train_loss:0.3094513556514379\n",
            "train_loss:0.21989803315400305\n",
            "train_loss:0.20482029066830548\n",
            "train_loss:0.3684068720684383\n",
            "train_loss:0.2947979346950323\n",
            "train_loss:0.3343808451635752\n",
            "train_loss:0.30051930327112286\n",
            "train_loss:0.39628631949084775\n",
            "train_loss:0.30454659601575024\n",
            "train_loss:0.2732841916629059\n",
            "train_loss:0.30250593444723095\n",
            "train_loss:0.19979160775641625\n",
            "train_loss:0.2583677335909223\n",
            "train_loss:0.36322419693281516\n",
            "train_loss:0.2183494064839173\n",
            "train_loss:0.2577043403484965\n",
            "train_loss:0.2674400461906076\n",
            "train_loss:0.2471820591663958\n",
            "train_loss:0.27441130768857214\n",
            "train_loss:0.26062061766877287\n",
            "train_loss:0.2880953755527453\n",
            "train_loss:0.25262392944199125\n",
            "train_loss:0.30160216361002795\n",
            "train_loss:0.30738438990508926\n",
            "train_loss:0.1814716918926926\n",
            "train_loss:0.21095056485244748\n",
            "train_loss:0.3121570257680852\n",
            "train_loss:0.2545130673032515\n",
            "train_loss:0.3003404309486416\n",
            "train_loss:0.3132049727820554\n",
            "train_loss:0.32237621360211877\n",
            "train_loss:0.3423751283349349\n",
            "train_loss:0.28213735987791044\n",
            "train_loss:0.3641631568550032\n",
            "train_loss:0.3458605491055404\n",
            "train_loss:0.19942890924474235\n",
            "train_loss:0.20019069560146818\n",
            "train_loss:0.19351505374923839\n",
            "train_loss:0.2684037808577527\n",
            "train_loss:0.2650388447637119\n",
            "train_loss:0.2455482614256073\n",
            "train_loss:0.2984894754109067\n",
            "train_loss:0.29823231909052333\n",
            "train_loss:0.27089316629692645\n",
            "train_loss:0.31392598158288765\n",
            "train_loss:0.3029647981647654\n",
            "train_loss:0.43224755945960297\n",
            "train_loss:0.26721433451269777\n",
            "train_loss:0.23541108598336027\n",
            "train_loss:0.22452799119614453\n",
            "train_loss:0.2523043656489843\n",
            "train_loss:0.28990883303111736\n",
            "train_loss:0.2554708923339902\n",
            "train_loss:0.18098132304755082\n",
            "train_loss:0.2581454378017572\n",
            "train_loss:0.3992180452375101\n",
            "train_loss:0.2674390109315835\n",
            "train_loss:0.3140066411227501\n",
            "train_loss:0.30084715926631506\n",
            "train_loss:0.25041337498566024\n",
            "train_loss:0.24208792057651451\n",
            "train_loss:0.2996424304452793\n",
            "train_loss:0.24457050467468747\n",
            "train_loss:0.22259589463469712\n",
            "train_loss:0.22271368057535793\n",
            "train_loss:0.28047133721770867\n",
            "train_loss:0.21948912233113937\n",
            "train_loss:0.2623255058843318\n",
            "train_loss:0.24967890379163868\n",
            "train_loss:0.24898887893319344\n",
            "train_loss:0.3570895797704492\n",
            "train_loss:0.38105663029166464\n",
            "train_loss:0.2759732325520767\n",
            "train_loss:0.20452812401989243\n",
            "train_loss:0.23381218601014753\n",
            "train_loss:0.407810178914955\n",
            "train_loss:0.25164640983176345\n",
            "train_loss:0.3059669610179511\n",
            "train_loss:0.3505739906148388\n",
            "train_loss:0.2531651590374636\n",
            "train_loss:0.29673664662153404\n",
            "train_loss:0.2236719870327899\n",
            "train_loss:0.35468126450709403\n",
            "train_loss:0.34886959448215005\n",
            "train_loss:0.35678557965494617\n",
            "train_loss:0.276295324400531\n",
            "train_loss:0.33747961398218157\n",
            "train_loss:0.25564997262350386\n",
            "train_loss:0.2853062660539573\n",
            "train_loss:0.2438272501029565\n",
            "train_loss:0.2728065001435918\n",
            "train_loss:0.21969853084764707\n",
            "train_loss:0.293507707850186\n",
            "train_loss:0.29846199844262494\n",
            "train_loss:0.21456315324455716\n",
            "train_loss:0.3108687984083357\n",
            "train_loss:0.23600118547098234\n",
            "train_loss:0.2950868413236811\n",
            "train_loss:0.34188889529074173\n",
            "train_loss:0.3490613104648327\n",
            "train_loss:0.2842184383047542\n",
            "train_loss:0.29001952174862217\n",
            "train_loss:0.2575475889298973\n",
            "train_loss:0.29855549138170995\n",
            "train_loss:0.333086245157442\n",
            "train_loss:0.22050510728739656\n",
            "train_loss:0.28966737018821026\n",
            "train_loss:0.2643979364026611\n",
            "train_loss:0.22002161497914144\n",
            "train_loss:0.28512943925947115\n",
            "train_loss:0.43848711665297346\n",
            "train_loss:0.29491616211567345\n",
            "train_loss:0.2323820332476047\n",
            "train_loss:0.3453040335130006\n",
            "train_loss:0.2638884629775087\n",
            "train_loss:0.2682837294487788\n",
            "train_loss:0.18264579058045868\n",
            "train_loss:0.35578007220512475\n",
            "train_loss:0.24903941040859448\n",
            "train_loss:0.19437227937595836\n",
            "train_loss:0.19594097123799428\n",
            "train_loss:0.22423317440871504\n",
            "train_loss:0.3048521590843065\n",
            "train_loss:0.2981267772466407\n",
            "train_loss:0.23831041919032223\n",
            "train_loss:0.3897862682123282\n",
            "train_loss:0.266625889515407\n",
            "train_loss:0.31873278191577614\n",
            "train_loss:0.22786700043809965\n",
            "train_loss:0.3765560169584299\n",
            "train_loss:0.22910376336273927\n",
            "train_loss:0.31168155593837243\n",
            "train_loss:0.24886820488818137\n",
            "train_loss:0.288730154662198\n",
            "train_loss:0.2703188704385321\n",
            "train_loss:0.2872090768094215\n",
            "train_loss:0.20092341528968233\n",
            "train_loss:0.30213287417100276\n",
            "train_loss:0.2983594170938397\n",
            "train_loss:0.20723696920974388\n",
            "train_loss:0.3021027854236122\n",
            "epoch:2  train_loss:0.30210279, train_acc:0.92195833, val_acc:0.91991667\n",
            "Accuracy:0.9231\n",
            "CPU times: user 10min 22s, sys: 4min 29s, total: 14min 52s\n",
            "Wall time: 9min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}